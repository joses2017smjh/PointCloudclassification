{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "# requires torch, torch_geometric, open3d, plotly\n",
    "# open3d needs python 3.10, anything higher will not work\n",
    "\n",
    "import torch\n",
    "from torch_geometric.datasets import ModelNet\n",
    "from torch_geometric.transforms import SamplePoints, NormalizeScale\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "import open3d as o3d\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import datetime\n",
    "import os\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pointtransformer fully implemented, consolidated to another file for import\n",
    "from pointtransformer import PointTransformerClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change to your device, also change device in pointtransformer.py file\n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modelnet10 dataset config\n",
    "\n",
    "num_points = 1024\n",
    "\n",
    "pre_transform = NormalizeScale()\n",
    "transform = SamplePoints(num_points)\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "root = 'data/ModelNet10'\n",
    "dataset_train = ModelNet(root=root, name='10', train=True, pre_transform=pre_transform, transform=transform)\n",
    "trainloader = DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "dataset_test = ModelNet(root=root, name='10', train=False, pre_transform=pre_transform, transform=transform)\n",
    "testloader = DataLoader(dataset_test, batch_size=batch_size)\n",
    "\n",
    "print(f'Number of training examples: {len(dataset_train)}')\n",
    "print(f'Number of test examples: {len(dataset_test)}')\n",
    "\n",
    "classes = dataset_test.raw_file_names\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 9843\n",
      "Number of test examples: 2468\n",
      "['airplane', 'bathtub', 'bed', 'bench', 'bookshelf', 'bottle', 'bowl', 'car', 'chair', 'cone', 'cup', 'curtain', 'desk', 'door', 'dresser', 'flower_pot', 'glass_box', 'guitar', 'keyboard', 'lamp', 'laptop', 'mantel', 'monitor', 'night_stand', 'person', 'piano', 'plant', 'radio', 'range_hood', 'sink', 'sofa', 'stairs', 'stool', 'table', 'tent', 'toilet', 'tv_stand', 'vase', 'wardrobe', 'xbox']\n"
     ]
    }
   ],
   "source": [
    "# modelnet40 dataset config\n",
    "\n",
    "num_points = 1024\n",
    "\n",
    "pre_transform = NormalizeScale()\n",
    "transform = SamplePoints(num_points)\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "root = 'data/ModelNet40'\n",
    "dataset_train = ModelNet(root=root, name='40', train=True, pre_transform=pre_transform, transform=transform)\n",
    "trainloader = DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "dataset_test = ModelNet(root=root, name='40', train=False, pre_transform=pre_transform, transform=transform)\n",
    "testloader = DataLoader(dataset_test, batch_size=batch_size)\n",
    "\n",
    "classes = [\"airplane\", \"bathtub\", \"bed\", \"bench\", \"bookshelf\", \"bottle\", \"bowl\", \"car\", \"chair\", \"cone\", \"cup\", \"curtain\", \"desk\", \"door\", \"dresser\", \"flower_pot\", \"glass_box\", \"guitar\", \"keyboard\", \"lamp\", \"laptop\", \"mantel\", \"monitor\", \"night_stand\", \"person\", \"piano\", \"plant\", \"radio\", \"range_hood\", \"sink\", \"sofa\", \"stairs\", \"stool\", \"table\", \"tent\", \"toilet\", \"tv_stand\", \"vase\", \"wardrobe\", \"xbox\"]\n",
    "\n",
    "print(f'Number of training examples: {len(dataset_train)}')\n",
    "print(f'Number of test examples: {len(dataset_test)}')\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "marker": {
          "color": "white",
          "size": 1
         },
         "mode": "markers",
         "type": "scatter3d",
         "x": {
          "bdata": "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",
          "dtype": "f4"
         },
         "y": {
          "bdata": "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",
          "dtype": "f4"
         },
         "z": {
          "bdata": "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",
          "dtype": "f4"
         }
        }
       ],
       "layout": {
        "scene": {
         "xaxis": {
          "visible": false
         },
         "yaxis": {
          "visible": false
         },
         "zaxis": {
          "visible": false
         }
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#f2f5fa"
            },
            "error_y": {
             "color": "#f2f5fa"
            },
            "marker": {
             "line": {
              "color": "rgb(17,17,17)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "rgb(17,17,17)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#A2B1C6",
             "gridcolor": "#506784",
             "linecolor": "#506784",
             "minorgridcolor": "#506784",
             "startlinecolor": "#A2B1C6"
            },
            "baxis": {
             "endlinecolor": "#A2B1C6",
             "gridcolor": "#506784",
             "linecolor": "#506784",
             "minorgridcolor": "#506784",
             "startlinecolor": "#A2B1C6"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "line": {
              "color": "#283442"
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "line": {
              "color": "#283442"
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#506784"
             },
             "line": {
              "color": "rgb(17,17,17)"
             }
            },
            "header": {
             "fill": {
              "color": "#2a3f5f"
             },
             "line": {
              "color": "rgb(17,17,17)"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#f2f5fa",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#f2f5fa"
          },
          "geo": {
           "bgcolor": "rgb(17,17,17)",
           "lakecolor": "rgb(17,17,17)",
           "landcolor": "rgb(17,17,17)",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#506784"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "dark"
          },
          "paper_bgcolor": "rgb(17,17,17)",
          "plot_bgcolor": "rgb(17,17,17)",
          "polar": {
           "angularaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "bgcolor": "rgb(17,17,17)",
           "radialaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "gridwidth": 2,
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3"
           },
           "yaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "gridwidth": 2,
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3"
           },
           "zaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "gridwidth": 2,
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#f2f5fa"
           }
          },
          "sliderdefaults": {
           "bgcolor": "#C8D4E3",
           "bordercolor": "rgb(17,17,17)",
           "borderwidth": 1,
           "tickwidth": 0
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "bgcolor": "rgb(17,17,17)",
           "caxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "updatemenudefaults": {
           "bgcolor": "#506784",
           "borderwidth": 0
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#283442",
           "linecolor": "#506784",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#283442",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#283442",
           "linecolor": "#506784",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#283442",
           "zerolinewidth": 2
          }
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# sanity check, plot the first element of training data\n",
    "\n",
    "data = dataset_test[0]\n",
    "\n",
    "fig = go.Figure(\n",
    "  data=[\n",
    "    go.Scatter3d(\n",
    "      x=data.pos[:,0], y=data.pos[:,1], z=data.pos[:,2],\n",
    "      mode='markers',\n",
    "      marker=dict(size=1, color=\"white\"))],\n",
    "  layout=dict(\n",
    "    scene=dict(\n",
    "      xaxis=dict(visible=False),\n",
    "      yaxis=dict(visible=False),\n",
    "      zaxis=dict(visible=False))))\n",
    "\n",
    "fig.update_layout(template='plotly_dark')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PointTransformerClassifier(\n",
       "  (backbone): PointTransformerBackbone(\n",
       "    (init_linear): Linear(in_features=3, out_features=32, bias=True)\n",
       "    (transformer1): PointTransformer(\n",
       "      (fcl1): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (head1): TransformerLayer(\n",
       "        (query): Linear(in_features=32, out_features=32, bias=True)\n",
       "        (key): Linear(in_features=32, out_features=32, bias=True)\n",
       "        (value): Linear(in_features=32, out_features=32, bias=True)\n",
       "        (pos_enc): Sequential(\n",
       "          (0): Conv1d(3, 32, kernel_size=(1,), stride=(1,))\n",
       "          (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "          (3): Conv1d(32, 32, kernel_size=(1,), stride=(1,))\n",
       "          (4): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (head2): TransformerLayer(\n",
       "        (query): Linear(in_features=32, out_features=32, bias=True)\n",
       "        (key): Linear(in_features=32, out_features=32, bias=True)\n",
       "        (value): Linear(in_features=32, out_features=32, bias=True)\n",
       "        (pos_enc): Sequential(\n",
       "          (0): Conv1d(3, 32, kernel_size=(1,), stride=(1,))\n",
       "          (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "          (3): Conv1d(32, 32, kernel_size=(1,), stride=(1,))\n",
       "          (4): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (head3): TransformerLayer(\n",
       "        (query): Linear(in_features=32, out_features=32, bias=True)\n",
       "        (key): Linear(in_features=32, out_features=32, bias=True)\n",
       "        (value): Linear(in_features=32, out_features=32, bias=True)\n",
       "        (pos_enc): Sequential(\n",
       "          (0): Conv1d(3, 32, kernel_size=(1,), stride=(1,))\n",
       "          (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "          (3): Conv1d(32, 32, kernel_size=(1,), stride=(1,))\n",
       "          (4): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (head4): TransformerLayer(\n",
       "        (query): Linear(in_features=32, out_features=32, bias=True)\n",
       "        (key): Linear(in_features=32, out_features=32, bias=True)\n",
       "        (value): Linear(in_features=32, out_features=32, bias=True)\n",
       "        (pos_enc): Sequential(\n",
       "          (0): Conv1d(3, 32, kernel_size=(1,), stride=(1,))\n",
       "          (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "          (3): Conv1d(32, 32, kernel_size=(1,), stride=(1,))\n",
       "          (4): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (fcl_multihead): Linear(in_features=128, out_features=32, bias=True)\n",
       "      (fcl2): Linear(in_features=32, out_features=32, bias=True)\n",
       "    )\n",
       "    (down1): TransitionDown(\n",
       "      (mlp): Sequential(\n",
       "        (0): Conv1d(32, 64, kernel_size=(1,), stride=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (transformer2): PointTransformer(\n",
       "      (fcl1): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (head1): TransformerLayer(\n",
       "        (query): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (key): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (value): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (pos_enc): Sequential(\n",
       "          (0): Conv1d(3, 64, kernel_size=(1,), stride=(1,))\n",
       "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "          (3): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "          (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (head2): TransformerLayer(\n",
       "        (query): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (key): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (value): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (pos_enc): Sequential(\n",
       "          (0): Conv1d(3, 64, kernel_size=(1,), stride=(1,))\n",
       "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "          (3): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "          (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (head3): TransformerLayer(\n",
       "        (query): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (key): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (value): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (pos_enc): Sequential(\n",
       "          (0): Conv1d(3, 64, kernel_size=(1,), stride=(1,))\n",
       "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "          (3): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "          (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (head4): TransformerLayer(\n",
       "        (query): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (key): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (value): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (pos_enc): Sequential(\n",
       "          (0): Conv1d(3, 64, kernel_size=(1,), stride=(1,))\n",
       "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "          (3): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "          (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (fcl_multihead): Linear(in_features=256, out_features=64, bias=True)\n",
       "      (fcl2): Linear(in_features=64, out_features=64, bias=True)\n",
       "    )\n",
       "    (down2): TransitionDown(\n",
       "      (mlp): Sequential(\n",
       "        (0): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n",
       "        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
       "        (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (transformer3): PointTransformer(\n",
       "      (fcl1): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (head1): TransformerLayer(\n",
       "        (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (value): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (pos_enc): Sequential(\n",
       "          (0): Conv1d(3, 128, kernel_size=(1,), stride=(1,))\n",
       "          (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "          (3): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
       "          (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (head2): TransformerLayer(\n",
       "        (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (value): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (pos_enc): Sequential(\n",
       "          (0): Conv1d(3, 128, kernel_size=(1,), stride=(1,))\n",
       "          (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "          (3): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
       "          (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (head3): TransformerLayer(\n",
       "        (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (value): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (pos_enc): Sequential(\n",
       "          (0): Conv1d(3, 128, kernel_size=(1,), stride=(1,))\n",
       "          (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "          (3): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
       "          (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (head4): TransformerLayer(\n",
       "        (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (value): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (pos_enc): Sequential(\n",
       "          (0): Conv1d(3, 128, kernel_size=(1,), stride=(1,))\n",
       "          (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "          (3): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
       "          (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (fcl_multihead): Linear(in_features=512, out_features=128, bias=True)\n",
       "      (fcl2): Linear(in_features=128, out_features=128, bias=True)\n",
       "    )\n",
       "    (down3): TransitionDown(\n",
       "      (mlp): Sequential(\n",
       "        (0): Conv1d(128, 256, kernel_size=(1,), stride=(1,))\n",
       "        (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "        (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (transformer4): PointTransformer(\n",
       "      (fcl1): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (head1): TransformerLayer(\n",
       "        (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (pos_enc): Sequential(\n",
       "          (0): Conv1d(3, 256, kernel_size=(1,), stride=(1,))\n",
       "          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "          (3): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "          (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (head2): TransformerLayer(\n",
       "        (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (pos_enc): Sequential(\n",
       "          (0): Conv1d(3, 256, kernel_size=(1,), stride=(1,))\n",
       "          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "          (3): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "          (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (head3): TransformerLayer(\n",
       "        (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (pos_enc): Sequential(\n",
       "          (0): Conv1d(3, 256, kernel_size=(1,), stride=(1,))\n",
       "          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "          (3): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "          (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (head4): TransformerLayer(\n",
       "        (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (pos_enc): Sequential(\n",
       "          (0): Conv1d(3, 256, kernel_size=(1,), stride=(1,))\n",
       "          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "          (3): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "          (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (fcl_multihead): Linear(in_features=1024, out_features=256, bias=True)\n",
       "      (fcl2): Linear(in_features=256, out_features=256, bias=True)\n",
       "    )\n",
       "    (down4): TransitionDown(\n",
       "      (mlp): Sequential(\n",
       "        (0): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
       "        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "        (4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (transformer5): PointTransformer(\n",
       "      (fcl1): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (head1): TransformerLayer(\n",
       "        (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (pos_enc): Sequential(\n",
       "          (0): Conv1d(3, 512, kernel_size=(1,), stride=(1,))\n",
       "          (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "          (3): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "          (4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (head2): TransformerLayer(\n",
       "        (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (pos_enc): Sequential(\n",
       "          (0): Conv1d(3, 512, kernel_size=(1,), stride=(1,))\n",
       "          (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "          (3): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "          (4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (head3): TransformerLayer(\n",
       "        (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (pos_enc): Sequential(\n",
       "          (0): Conv1d(3, 512, kernel_size=(1,), stride=(1,))\n",
       "          (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "          (3): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "          (4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (head4): TransformerLayer(\n",
       "        (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (pos_enc): Sequential(\n",
       "          (0): Conv1d(3, 512, kernel_size=(1,), stride=(1,))\n",
       "          (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "          (3): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "          (4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (fcl_multihead): Linear(in_features=2048, out_features=512, bias=True)\n",
       "      (fcl2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (classification_head): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.3, inplace=False)\n",
       "    (4): Linear(in_features=256, out_features=40, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a new pointtransformer\n",
    "pointtransformer = PointTransformerClassifier(num_classes=40)\n",
    "pointtransformer.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 40])\n"
     ]
    }
   ],
   "source": [
    "# quick sanity check\n",
    "test_data = torch.rand(batch_size, num_points, 3).to(device)\n",
    "\n",
    "output = pointtransformer(test_data)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training hyperparameters\n",
    "num_epochs = 50\n",
    "learning_rate = 0.01\n",
    "momentum = 0.7\n",
    "weight_decay = 0\n",
    "\n",
    "optimizer = optim.SGD(pointtransformer.parameters(), lr=learning_rate, momentum=momentum, weight_decay=weight_decay)\n",
    "criterion = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load a pointtransformer from a saved state\n",
    "checkpoint_pointnet = torch.load(\"pointtransformer_modelnet40/187.pth\", map_location=torch.device(device))\n",
    "pointtransformer.load_state_dict(checkpoint_pointnet['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training loop\n",
    "\n",
    "directory = \"./pointtransformer_modelnet40_final_again\"\n",
    "os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "for i in range(4):\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        train_accuracy = 0\n",
    "        test_accuracy = 0\n",
    "        loss_avg = 0\n",
    "        count = 0\n",
    "\n",
    "        pointtransformer.train()\n",
    "        for data in trainloader:\n",
    "\n",
    "            clouds = data.pos.view(data.batch[-1]+1, num_points, 3).to(device)\n",
    "            labels = data.y.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = pointtransformer(clouds)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            loss_avg += loss.item()\n",
    "            count += 1\n",
    "        \n",
    "        loss_avg = loss_avg/count\n",
    "        \n",
    "        pointtransformer.eval()\n",
    "        with torch.no_grad():\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for data in testloader:\n",
    "                \n",
    "                clouds = data.pos.view(data.batch[-1]+1, num_points, 3).to(device)\n",
    "                labels = data.y.to(device)\n",
    "                \n",
    "                outputs = pointtransformer(clouds)\n",
    "\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "            test_accuracy = correct/total\n",
    "            correct = 0\n",
    "            total = 0\n",
    "        \n",
    "        #print(\"{}   [Epoch {:3}]  Loss: {:8.4}  Accuracy:   {:8.4}%\".format(datetime.datetime.now(), epoch, loss_avg, 100*accuracy))\n",
    "        #print(\"{:8.4},{:8.4},{:8.4}\".format(loss_avg, 100*train_accuracy, 100*test_accuracy))\n",
    "        print(\"{:8.4},{:8.4}\".format(loss_avg, 100*test_accuracy))\n",
    "\n",
    "        torch.save(\n",
    "            {'model_state_dict': pointtransformer.state_dict()},\n",
    "            directory + \"/{:03d}\".format(epoch+i*num_epochs) + \".pth\")\n",
    "    \n",
    "    learning_rate *= 0.1\n",
    "    optimizer = optim.SGD(pointtransformer.parameters(), lr=learning_rate, momentum=momentum, weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-21 14:52:46.382171   Accuracy:      86.79%\n"
     ]
    }
   ],
   "source": [
    "# test evaluation\n",
    "\n",
    "pointtransformer.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for data in testloader:\n",
    "        \n",
    "        clouds = data.pos.view(data.batch[-1]+1, num_points, 3).to(device)\n",
    "        labels = data.y.to(device)\n",
    "            \n",
    "        outputs = pointtransformer(clouds)\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    accuracy = correct/total\n",
    "\n",
    "    print(\"{}   Accuracy:   {:8.4}%\".format(datetime.datetime.now(), 100*accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test on random point clouds\n",
    "\n",
    "idx = random.randint(0, len(dataset_test))\n",
    "data = dataset_test[idx]\n",
    "cloud = data.pos.view(1, num_points, 3).to(device)\n",
    "\n",
    "output = pointtransformer(cloud)\n",
    "probabilities = 100*F.softmax(output.transpose(1,0), dim=0)\n",
    "\n",
    "_, predicted = torch.max(output.data, 1)\n",
    "label = data.y\n",
    "\n",
    "print('Predicted Class: {}    Certainty: {:8.4}   Actual Class:   {}'.format(classes[predicted.item()], probabilities[predicted.item()].item(), classes[label.item()]))\n",
    "\n",
    "fig = go.Figure(\n",
    "  data=[\n",
    "    go.Scatter3d(\n",
    "      x=data.pos[:,0], y=data.pos[:,1], z=data.pos[:,2],\n",
    "      mode='markers',\n",
    "      marker=dict(size=1, color=\"white\"))],\n",
    "  layout=dict(\n",
    "    scene=dict(\n",
    "      xaxis=dict(visible=False),\n",
    "      yaxis=dict(visible=False),\n",
    "      zaxis=dict(visible=False))))\n",
    "\n",
    "fig.update_layout(template='plotly_dark')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(p.numel() for p in pointtransformer.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = []\n",
    "true = []\n",
    "\n",
    "for data in testloader:\n",
    "    \n",
    "    clouds = data.pos.view(data.batch[-1]+1, num_points, 3).to(device)\n",
    "    labels = data.y.to(device)\n",
    "\n",
    "    output = pointtransformer(clouds)\n",
    "\n",
    "    output = (torch.max(torch.exp(output), 1)[1]).data.cpu().numpy()\n",
    "    pred.extend(output) # Save Prediction\n",
    "    \n",
    "    labels = labels.data.cpu().numpy()\n",
    "    true.extend(labels) # Save Truth\n",
    "\n",
    "cf_matrix = confusion_matrix(true, pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cf_matrix,\n",
    "                              display_labels=classes)\n",
    "disp.plot(cmap=plt.cm.Blues, xticks_rotation=\"vertical\")\n",
    "\n",
    "plt.savefig(\"pointtransformer_modelnet10_confusion_matrix.svg\", format=\"svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.1101%\n",
      "  0.4405%\n",
      "  0.3304%\n",
      "     0.0%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 30\u001b[0m\n\u001b[0;32m     27\u001b[0m clouds \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mpos\u001b[38;5;241m.\u001b[39mview(data\u001b[38;5;241m.\u001b[39mbatch[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, num_points, \u001b[38;5;241m3\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     28\u001b[0m labels \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39my\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 30\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mpointtransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclouds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m _, predicted \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(outputs\u001b[38;5;241m.\u001b[39mdata, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     33\u001b[0m total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Joshua\\anaconda3\\envs\\pointcloud\\lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Joshua\\anaconda3\\envs\\pointcloud\\lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Joshua\\Documents\\computer_science\\ai_535\\PointCloudclassification\\pointtransformer.py:193\u001b[0m, in \u001b[0;36mPointTransformerClassifier.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    190\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m    191\u001b[0m \n\u001b[0;32m    192\u001b[0m     \u001b[38;5;66;03m# backbone returns global feature vector\u001b[39;00m\n\u001b[1;32m--> 193\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackbone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    194\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassification_head(x)\n\u001b[0;32m    196\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\Joshua\\anaconda3\\envs\\pointcloud\\lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Joshua\\anaconda3\\envs\\pointcloud\\lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Joshua\\Documents\\computer_science\\ai_535\\PointCloudclassification\\pointtransformer.py:160\u001b[0m, in \u001b[0;36mPointTransformerBackbone.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    157\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mlayer_norm(x, normalized_shape\u001b[38;5;241m=\u001b[39m[x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]])\n\u001b[0;32m    159\u001b[0m x, p \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer1(x, p)\n\u001b[1;32m--> 160\u001b[0m x, p \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdown1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    161\u001b[0m x, p \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer2(x, p)\n\u001b[0;32m    162\u001b[0m x, p \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdown2(x, p)\n",
      "File \u001b[1;32mc:\\Users\\Joshua\\anaconda3\\envs\\pointcloud\\lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Joshua\\anaconda3\\envs\\pointcloud\\lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Joshua\\Documents\\computer_science\\ai_535\\PointCloudclassification\\pointtransformer.py:125\u001b[0m, in \u001b[0;36mTransitionDown.forward\u001b[1;34m(self, x, p)\u001b[0m\n\u001b[0;32m    122\u001b[0m idx \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], (\u001b[38;5;28mint\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m4\u001b[39m),))\n\u001b[0;32m    124\u001b[0m \u001b[38;5;66;03m# transform each point into 2x higher feature space\u001b[39;00m\n\u001b[1;32m--> 125\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp(\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    126\u001b[0m p \u001b[38;5;241m=\u001b[39m p[:,idx,:]\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x, p\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for num_points in [256, 512, 1024, 2048, 4096]:\n",
    "\n",
    "    pre_transform = NormalizeScale()\n",
    "    transform = SamplePoints(num_points)\n",
    "\n",
    "    batch_size = 64\n",
    "\n",
    "    root = 'data/ModelNet40'\n",
    "    dataset_train = ModelNet(root=root, name='40', train=True, pre_transform=pre_transform, transform=transform)\n",
    "    trainloader = DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    dataset_test = ModelNet(root=root, name='40', train=False, pre_transform=pre_transform, transform=transform)\n",
    "    testloader = DataLoader(dataset_test, batch_size=batch_size)\n",
    "\n",
    "    classes = dataset_test.raw_file_names\n",
    "    \n",
    "    accuracy = 0\n",
    "    total = 0\n",
    "    correct = 0\n",
    "\n",
    "    pointtransformer.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for data in testloader:\n",
    "            \n",
    "            clouds = data.pos.view(data.batch[-1]+1, num_points, 3).to(device)\n",
    "            labels = data.y.to(device)\n",
    "                \n",
    "            outputs = pointtransformer(clouds)\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        accuracy = correct/total\n",
    "\n",
    "        print(\"{:8.4}%\".format(100*accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pointcloud",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
