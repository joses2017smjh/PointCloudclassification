{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "# requires torch, torch_geometric, open3d, plotly\n",
    "# open3d needs python 3.10, anything higher will not work\n",
    "\n",
    "import torch\n",
    "from torch_geometric.datasets import ModelNet\n",
    "from torch_geometric.transforms import SamplePoints, NormalizeScale\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "import open3d as o3d\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import datetime\n",
    "import os\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pointnet fully implemented, consolidated to another file for import\n",
    "from pointnet import PointNetClassifier, PointNetClassificationLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change to your device, also change device in pointnet.py file\n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modelnet10 dataset config\n",
    "\n",
    "num_points = 1024\n",
    "\n",
    "pre_transform = NormalizeScale()\n",
    "transform = SamplePoints(num_points)\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "root = 'data/ModelNet10'\n",
    "dataset_train = ModelNet(root=root, name='10', train=True, pre_transform=pre_transform, transform=transform)\n",
    "trainloader = DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "dataset_test = ModelNet(root=root, name='10', train=False, pre_transform=pre_transform, transform=transform)\n",
    "testloader = DataLoader(dataset_test, batch_size=batch_size)\n",
    "\n",
    "print(f'Number of training examples: {len(dataset_train)}')\n",
    "print(f'Number of test examples: {len(dataset_test)}')\n",
    "\n",
    "classes = dataset_test.raw_file_names\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modelnet40 dataset config\n",
    "\n",
    "num_points = 1024\n",
    "\n",
    "pre_transform = NormalizeScale()\n",
    "transform = SamplePoints(num_points)\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "root = 'data/ModelNet40'\n",
    "dataset_train = ModelNet(root=root, name='40', train=True, pre_transform=pre_transform, transform=transform)\n",
    "trainloader = DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "dataset_test = ModelNet(root=root, name='40', train=False, pre_transform=pre_transform, transform=transform)\n",
    "testloader = DataLoader(dataset_test, batch_size=batch_size)\n",
    "\n",
    "classes = [\"airplane\", \"bathtub\", \"bed\", \"bench\", \"bookshelf\", \"bottle\", \"bowl\", \"car\", \"chair\", \"cone\", \"cup\", \"curtain\", \"desk\", \"door\", \"dresser\", \"flower_pot\", \"glass_box\", \"guitar\", \"keyboard\", \"lamp\", \"laptop\", \"mantel\", \"monitor\", \"night_stand\", \"person\", \"piano\", \"plant\", \"radio\", \"range_hood\", \"sink\", \"sofa\", \"stairs\", \"stool\", \"table\", \"tent\", \"toilet\", \"tv_stand\", \"vase\", \"wardrobe\", \"xbox\"]\n",
    "\n",
    "print(f'Number of training examples: {len(dataset_train)}')\n",
    "print(f'Number of test examples: {len(dataset_test)}')\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check, plot the first element of training data\n",
    "\n",
    "data = dataset_test[0]\n",
    "\n",
    "fig = go.Figure(\n",
    "  data=[\n",
    "    go.Scatter3d(\n",
    "      x=data.pos[:,0], y=data.pos[:,1], z=data.pos[:,2],\n",
    "      mode='markers',\n",
    "      marker=dict(size=1, color=\"white\"))],\n",
    "  layout=dict(\n",
    "    scene=dict(\n",
    "      xaxis=dict(visible=False),\n",
    "      yaxis=dict(visible=False),\n",
    "      zaxis=dict(visible=False))))\n",
    "\n",
    "fig.update_layout(template='plotly_dark')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PointNetClassifier(\n",
       "  (backbone): PointNetBackbone(\n",
       "    (tnet1): Transformer(\n",
       "      (mlp): Sequential(\n",
       "        (0): Conv1d(3, 64, kernel_size=(1,), stride=(1,))\n",
       "        (1): ReLU()\n",
       "        (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n",
       "        (4): ReLU()\n",
       "        (5): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (7): ReLU()\n",
       "        (8): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (fcl): Sequential(\n",
       "        (0): Linear(in_features=1024, out_features=512, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): Linear(in_features=512, out_features=256, bias=True)\n",
       "        (4): ReLU()\n",
       "        (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): Linear(in_features=256, out_features=9, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (mlp1): Sequential(\n",
       "      (0): Conv1d(3, 64, kernel_size=(1,), stride=(1,))\n",
       "      (1): ReLU()\n",
       "      (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (4): ReLU()\n",
       "      (5): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (tnet2): Transformer(\n",
       "      (mlp): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "        (1): ReLU()\n",
       "        (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n",
       "        (4): ReLU()\n",
       "        (5): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (7): ReLU()\n",
       "        (8): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (fcl): Sequential(\n",
       "        (0): Linear(in_features=1024, out_features=512, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): Linear(in_features=512, out_features=256, bias=True)\n",
       "        (4): ReLU()\n",
       "        (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): Linear(in_features=256, out_features=4096, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (mlp2): Sequential(\n",
       "      (0): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (1): ReLU()\n",
       "      (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n",
       "      (4): ReLU()\n",
       "      (5): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (6): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))\n",
       "      (7): ReLU()\n",
       "      (8): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (classification_head): Sequential(\n",
       "    (0): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "    (6): Dropout(p=0.3, inplace=False)\n",
       "    (7): Linear(in_features=256, out_features=40, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a new pointnet\n",
    "pointnet = PointNetClassifier(num_classes=40)\n",
    "pointnet.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick sanity check\n",
    "test_data = torch.rand(batch_size, num_points, 3).to(device)\n",
    "\n",
    "output, A = pointnet(test_data)\n",
    "print(A.shape)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training hyperparameters\n",
    "num_epochs = 50\n",
    "learning_rate = 0.1\n",
    "momentum = 0.9\n",
    "weight_decay = 0\n",
    "reg_weight = 0.001\n",
    "\n",
    "optimizer = optim.SGD(pointnet.parameters(), lr=learning_rate, momentum=momentum, weight_decay=weight_decay)\n",
    "criterion = PointNetClassificationLoss(reg_weight=reg_weight).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load a pointnet from a saved state\n",
    "checkpoint_pointnet = torch.load(\"pointnet_modelnet40/189.pth\", map_location=torch.device(device))\n",
    "pointnet.load_state_dict(checkpoint_pointnet['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training loop\n",
    "\n",
    "directory = \"./pointnet_modelnet40\"\n",
    "os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "for i in range(4):\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        accuracy = 0\n",
    "        loss_avg = 0\n",
    "        count = 0\n",
    "\n",
    "        pointnet.train()\n",
    "        for data in trainloader:\n",
    "\n",
    "            clouds = data.pos.view(data.batch[-1]+1, num_points, 3).to(device)\n",
    "            labels = data.y.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs, A = pointnet(clouds)\n",
    "            loss = criterion(outputs, labels, A)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            loss_avg += loss.item()\n",
    "            count += 1\n",
    "        \n",
    "        loss_avg = loss_avg/count\n",
    "        \n",
    "        pointnet.eval()\n",
    "        with torch.no_grad():\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for data in testloader:\n",
    "                \n",
    "                clouds = data.pos.view(data.batch[-1]+1, num_points, 3).to(device)\n",
    "                labels = data.y.to(device)\n",
    "                \n",
    "                outputs, _ = pointnet(clouds)\n",
    "\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "            accuracy = correct/total\n",
    "        \n",
    "        #print(\"{}   [Epoch {:3}]  Loss: {:8.4}  Accuracy:   {:8.4}%\".format(datetime.datetime.now(), epoch, loss_avg, 100*accuracy))\n",
    "        print(\"{:8.4},{:8.4}\".format(loss_avg, 100*accuracy))\n",
    "\n",
    "        torch.save(\n",
    "            {'model_state_dict': pointnet.state_dict()},\n",
    "            directory + \"/{:03d}\".format(epoch+i*num_epochs) + \".pth\")\n",
    "    \n",
    "    learning_rate *= 0.1\n",
    "    optimizer = optim.SGD(pointnet.parameters(), lr=learning_rate, momentum=momentum, weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test evaluation\n",
    "\n",
    "pointnet.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for data in testloader:\n",
    "        \n",
    "        clouds = data.pos.view(data.batch[-1]+1, num_points, 3).to(device)\n",
    "        labels = data.y.to(device)\n",
    "            \n",
    "        outputs, _ = pointnet(clouds)\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    accuracy = correct/total\n",
    "\n",
    "    print(\"{}   Accuracy:   {:8.4}%\".format(datetime.datetime.now(), 100*accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test on random point clouds\n",
    "\n",
    "idx = random.randint(0, len(dataset_test))\n",
    "data = dataset_test[idx]\n",
    "cloud = data.pos.view(1, num_points, 3).to(device)\n",
    "\n",
    "output, _ = pointnet(cloud)\n",
    "probabilities = 100*F.softmax(output.transpose(1,0), dim=0)\n",
    "\n",
    "_, predicted = torch.max(output.data, 1)\n",
    "label = data.y\n",
    "\n",
    "print('Predicted Class: {}    Certainty: {:8.4}   Actual Class:   {}'.format(classes[predicted.item()], probabilities[predicted.item()].item(), classes[label.item()]))\n",
    "\n",
    "fig = go.Figure(\n",
    "  data=[\n",
    "    go.Scatter3d(\n",
    "      x=data.pos[:,0], y=data.pos[:,1], z=data.pos[:,2],\n",
    "      mode='markers',\n",
    "      marker=dict(size=1, color=\"white\"))],\n",
    "  layout=dict(\n",
    "    scene=dict(\n",
    "      xaxis=dict(visible=False),\n",
    "      yaxis=dict(visible=False),\n",
    "      zaxis=dict(visible=False))))\n",
    "\n",
    "fig.update_layout(template='plotly_dark')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(p.numel() for p in pointnet.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = []\n",
    "true = []\n",
    "\n",
    "for data in testloader:\n",
    "    \n",
    "    clouds = data.pos.view(data.batch[-1]+1, num_points, 3).to(device)\n",
    "    labels = data.y.to(device)\n",
    "\n",
    "    output, _ = pointnet(clouds)\n",
    "\n",
    "    output = (torch.max(torch.exp(output), 1)[1]).data.cpu().numpy()\n",
    "    pred.extend(output) # Save Prediction\n",
    "    \n",
    "    labels = labels.data.cpu().numpy()\n",
    "    true.extend(labels) # Save Truth\n",
    "\n",
    "cf_matrix = confusion_matrix(true, pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cf_matrix,\n",
    "                              display_labels=classes)\n",
    "disp.plot(cmap=plt.cm.Blues, xticks_rotation=\"vertical\")\n",
    "\n",
    "plt.savefig(\"pointnet_modelnet10_confusion_matrix.svg\", format=\"svg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   85.86%\n",
      "    88.7%\n",
      "   89.42%\n",
      "   89.75%\n",
      "   89.34%\n"
     ]
    }
   ],
   "source": [
    "for num_points in [256, 512, 1024, 2048, 4096]:\n",
    "\n",
    "    pre_transform = NormalizeScale()\n",
    "    transform = SamplePoints(num_points)\n",
    "\n",
    "    batch_size = 64\n",
    "\n",
    "    root = 'data/ModelNet40'\n",
    "    dataset_train = ModelNet(root=root, name='40', train=True, pre_transform=pre_transform, transform=transform)\n",
    "    trainloader = DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    dataset_test = ModelNet(root=root, name='40', train=False, pre_transform=pre_transform, transform=transform)\n",
    "    testloader = DataLoader(dataset_test, batch_size=batch_size)\n",
    "\n",
    "    classes = dataset_test.raw_file_names\n",
    "    \n",
    "    accuracy = 0\n",
    "    total = 0\n",
    "    correct = 0\n",
    "\n",
    "    pointnet.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for data in testloader:\n",
    "            \n",
    "            clouds = data.pos.view(data.batch[-1]+1, num_points, 3).to(device)\n",
    "            labels = data.y.to(device)\n",
    "                \n",
    "            outputs, _ = pointnet(clouds)\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        accuracy = correct/total\n",
    "\n",
    "        print(\"{:8.4}%\".format(100*accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pointcloud",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
